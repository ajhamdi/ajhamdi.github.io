<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.6.2">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Abdullah Hamdi">

  
  
  
    
  
  <meta name="description" content="Abdullah Hamdi: PhD Student in Computer Science (Computer Vision) working on deep learning and understanding artificial neural networks.">

  
  <link rel="alternate" hreflang="en-us" href="https://abdullahamdi.com/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119904508-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           document.location = url;
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target);  
  }

  gtag('js', new Date());
  gtag('config', 'UA-119904508-2', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Abdullah Hamdi">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://abdullahamdi.com/">

  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@Eng_Hemdi">
  <meta property="twitter:creator" content="@Eng_Hemdi">
  
  <meta property="og:site_name" content="Abdullah Hamdi">
  <meta property="og:url" content="https://abdullahamdi.com/">
  <meta property="og:title" content="Abdullah Hamdi">
  <meta property="og:description" content="Abdullah Hamdi: PhD Student in Computer Science (Computer Vision) working on deep learning and understanding artificial neural networks."><meta property="og:image" content="https://abdullahamdi.com/img/avatar.png">
  <meta property="twitter:image" content="https://abdullahamdi.com/img/avatar.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2023-09-25T00:00:00&#43;01:00">
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite","url": "https://abdullahamdi.com/"
}
</script>


  


  


  





  <title>Abdullah Hamdi</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    
      <a class="navbar-brand" href="/">Abdullah Hamdi</a>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about" data-target="#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#video" data-target="#video"><span>Videos</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications" data-target="#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#skills" data-target="#skills"><span>Experience</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact" data-target="#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/cv.pdf"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      

      

    </ul>

  </div>
</nav>


  











<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  









<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="portrait" src="/authors/admin/avatar_hud06ea9892c72892c2f4743d7d8e66c7e_172167_250x250_fill_lanczos_center_2.png" alt="Avatar">
      

      <div class="portrait-title">
        <h2>Abdullah Hamdi</h2>
        <h3>Postdoc Researcher; Computer Vision</h3>

        
        <h3>
          <a href="https://www.robots.ox.ac.uk/~vgg/" target="_blank" rel="noopener">
          <span>VGG lab, University of Oxford</span>
          </a>
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="/#contact" >
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://twitter.com/Eng_Hemdi" target="_blank" rel="noopener">
            <i class="fab fa-twitter big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?user=tQkWPKAAAAAJ&amp;hl=en" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://www.researchgate.net/profile/Abdullah_Hamdi2" target="_blank" rel="noopener">
            <i class="ai ai-researchgate big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://github.com/ajhamdi" target="_blank" rel="noopener">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://cemse.kaust.edu.sa/ivul/people/person/abdullah-hamdi" target="_blank" rel="noopener">
            <i class="fas fa-user-graduate big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://sa.linkedin.com/in/abdullah-hamdi-9ba26689" target="_blank" rel="noopener">
            <i class="fab fa-linkedin big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="/files/cv.pdf" >
            <i class="ai ai-cv big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    <h1>Biography</h1>

    <p>I am a postdoctoral research fellow in machine learning and computer vision at the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geomtry Group</a> of the <a href="https://www.ox.ac.uk/">University of Oxford</a> with Prof. <a href="https://scholar.google.com/citations?hl=en&amp;user=UZ5wscMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Andrew Zisserman</a> and Prof. <a href="https://scholar.google.com/citations?user=bRT7t28AAAAJ&amp;hl=en">Andrea Vedaldi</a>. Prior to that, I earned PhD and MS degrees in Electrical an computer Engineering (Computer Vision) from <a href="https://kaust.edu.sa">KAUST</a>, working on 3D understanding with deep neural networks. I was part of the Image and Video Understanding Laboratory (<a href="https://ivul.kaust.edu.sa">IVUL</a>) in the Visual Computing Center (<a href="https://vcc.kaust.edu.sa">VCC</a>), advised by <a href="http://bernardghanem.com">Bernard Ghanem</a>. I was a visiting PhD student with Prof <a href="https://niessnerlab.org/">Matthias Niessner</a> at <a href="https://www.tum.de/">TUM</a> in 2022 for 5 months in Munich. I received my my undergraduate degree form <a href="http://www.kfupm.edu.sa/">KFUPM</a> in Electrical Engineering. My carear goal is to develop robust deep learning tools for 3D understanding and creation and to expand the access of AI to disadvantaged groups in the Arabic region. [<a href="https://youtu.be/ZOA6MWqs1OQ">video</a>, <a href="https://www.kaust.edu.sa/en/news/student-focus-abdullah-hamdi">article</a>, <a href="https://youtu.be/pWwzOmbOEUQ">TedX talk</a>]. I am also the founder and president of <a href="https://fihm.ai/">fihm.ai</a> (biggest Arabic online AI platform).</p>


    <div class="row">

      
      <div class="col-md-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Multi-view for 3D Understanding and Generation</li>
          
          <li>Robustness of Deep Learning</li>
          
          <li>3D Deep Learning</li>
          
          <li>Simulation for Vision</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Electrical and Computer Engineering (GPA 3.7/4), 2023</p>
              <p class="institution">King Abdullah University of Science and Technology</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MSc in Electrical Engineering (GPA 4/4), 2018</p>
              <p class="institution">King Abdullah University of Science and Technology</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BSc in Electrical Engineering (GPA 3.97/4), 2016</p>
              <p class="institution">King Fahd University of Petroleum and Minerals</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="video" class="home-section wg-video   "  >
    <div class="container">
      


<div class="row">
    
    <div class="col-lg-12 section-heading" style="text-align: center;">
        <h1>Videos</h1>
    </div>
    

    <div class="col-lg-12">
        <p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/pWwzOmbOEUQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/ZOA6MWqs1OQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
</p>

    </div>

    <style>
        #news-table td:first-child {
            width: 1%;
            white-space: nowrap;
            font-weight: bold;
            text-align: center;
             
        }
    </style>

    
</div>
    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="publications" class="home-section wg-pages   "  >
    <div class="container">
      








  























  





  


<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Publications</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    <!-- raw HTML omitted -->


    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/jinjie-mai/">Jinjie Mai</a></span>, <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/silvio-giancola/">Silvio Giancola</a></span>, <span><a href="/authors/chen-zhao/">Chen Zhao</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="http://iccv2023.thecvf.com"><strong>ICCV&rsquo;23</strong></a> <strong>[oral]</strong>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/egoloc-iccv/">
      <img src="/publication/egoloc-iccv/featured_hu2e97c705b1a48a71a0b12b0068850ce1_1108735_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/egoloc-iccv/">EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries</a>
  </h3>

  
  <div class="article-style">
    <p>With the recent advances in video and 3D understanding, novel 4D spatio-temporal methods fusing both concepts have emerged. Towards this direction, the Ego4D Episodic Memory Benchmark proposed a task for Visual Queries with 3D Localization (VQ3D). Given an egocentric video clip and an image crop depicting a query object, the goal is to localize the 3D position of the center of that query object with respect to the camera pose of a query frame. Current methods tackle the problem of VQ3D by unprojecting the 2D localization results of the sibling task Visual Queries with 2D Localization (VQ2D) into 3D predictions. Yet, we point out that the low number of camera poses caused by camera re-localization from previous VQ3D methods severally hinders their overall success rate. In this work, we formalize a pipeline (we dub EgoLoc) that better entangles 3D multiview geometry with 2D object retrieval from egocentric videos. Our approach involves estimating more robust camera poses and aggregating multi-view 3D displacements by leveraging the 2D detection confidence, which enhances the success rate of object queries and leads to a significant improvement in the VQ3D baseline performance. Specifically, our approach achieves an overall success rate of up to 87.12%, which sets a new state-of-the-art result in the VQ3D task. We provide a comprehensive empirical analysis of the VQ3D task and existing solutions and highlight the remaining challenges in VQ3D. The code and models will be released upon publication to set a new standard for the VQ3D task</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2212.06969" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/egoloc-iccv/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/Wayne-Mai/EgoLoc" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/12PApRsVHOvmnNnBQS4Ywj7BgTQ_XIypA/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://openaccess.thecvf.com/content/ICCV2023/html/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.html" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>, <span>Matthias Nie√üner</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    August 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://ai3dcc.github.io/index.html"><em>ICCV&rsquo;23</em> Workshop on AI for 3D Content Creation</a>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/sparf/">
      <img src="/publication/sparf/featured_hu30d566bab986af731b8219d70df2b885_303813_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/sparf/">SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input Images</a>
  </h3>

  
  <div class="article-style">
    <p>Recent advances in Neural Radiance Fields (NeRFs) treat the problem of novel view synthesis as Sparse Radiance Field (SRF) optimization using sparse voxels for efficient and fast rendering (Plenoxels,InstantNGP). In order to leverage machine learning and adoption of SRFs as a 3D representation, we present SPARF, a large-scale ShapeNet-based synthetic dataset for novel view synthesis consisting of ~ 17 million images rendered from nearly 40,000 shapes at high resolution (400 X 400 pixels). The dataset is orders of magnitude larger than existing synthetic datasets for novel view synthesis and includes more than one million 3D-optimized radiance fields with multiple voxel resolutions. Furthermore, we propose a novel pipeline (SuRFNet) that learns to generate sparse voxel radiance fields from only few views. This is done by using the densely collected SPARF dataset and 3D sparse convolutions. SuRFNet employs partial SRFs from few/one images and a specialized SRF loss to learn to generate high-quality sparse voxel radiance fields that can be rendered from novel views. Our approach achieves state-of-the-art results in the task of unconstrained novel view synthesis based on few views on ShapeNet as compared to recent baselines.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2212.09100.pdf" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2212.09100" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/sparf/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/sparf_pytorch" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/sparf_pytorch" target="_blank" rel="noopener">
  Dataset
</a>



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://abdullahamdi.com/sparf/" target="_blank" rel="noopener">
  Project
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1W-SMSFlH7uAsA_Mu4OhZu052uAG3Dauk/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://youtu.be/VcjypZ0hp4w" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/guocheng-qian/">Guocheng Qian</a></span>, <span><a href="/authors/jinjie-mai/">Jinjie Mai</a></span>, <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/jian-ren/">Jian Ren</a></span>, <span><a href="/authors/aliaksandr-siarohin/">Aliaksandr Siarohin</a></span>, <span><a href="/authors/bing-li/">Bing Li</a></span>, <span><a href="/authors/hsin-ying-lee/">Hsin-Ying Lee</a></span>, <span><a href="/authors/ivan-skorokhodov/">Ivan Skorokhodov</a></span>, <span><a href="/authors/peter-wonka/">Peter Wonka</a></span>, <span><a href="/authors/sergey-tulyakov/">Sergey Tulyakov</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July 2023
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In Arxiv
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/magic123/">
      <img src="/publication/magic123/featured_hua037d7525d1afc030ce750cfa60049f6_271902_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/magic123/">Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</a>
  </h3>

  
  <div class="article-style">
    <p>We present <code>Magic123</code>, a two-stage coarse-to-fine solution for high-quality, textured 3D meshes generation from a single unposed image in the wild using both 2D and 3D priors. In the first stage, we optimize a neural radiance field to produce a coarse geometry. In the second stage, we adopt a memory-efficient differentiable mesh representation to yield a high-resolution mesh with a visually appealing texture. In both stages, the 3D content is learned through reference view supervision and novel views guided by both 2D and 3D diffusion priors. We introduce a single tradeoff parameter between the 2D and 3D priors to control exploration (more imaginative) and exploitation (more precise) of the generated geometry. Additionally, We employ textual inversion and monocular depth regularization to encourage consistent appearances across views and to prevent degenerate solutions, respectively. Magic123 demonstrates a significant improvement over previous image-to-3D techniques, as validated through extensive experiments on synthetic benchmarks and diverse real-world images.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2306.17843" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2306.17843.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/magic123/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/guochengqian/Magic123" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://guochengqian.github.io/project/magic123/" target="_blank" rel="noopener">
  Dataset
</a>



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://guochengqian.github.io/project/magic123/" target="_blank" rel="noopener">
  Project
</a>











  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/silvio-giancola/">Silvio Giancola</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://iclr.cc/Conferences/2023"><strong>ICLR&rsquo;23</strong></a>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/voint-cloud/">
      <img src="/publication/voint-cloud/featured_hudee14ef875676280b8288a2cb7a97019_205713_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/voint-cloud/">Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding</a>
  </h3>

  
  <div class="article-style">
    <p>Multi-view projection methods have demonstrated promising performance on 3D understanding tasks like 3D classification and segmentation. However, it remains unclear how to combine such multi-view methods with the widely available 3D point clouds. Previous methods use unlearned heuristics to combine features at the point level. To this end, we introduce the concept of the multi-view point cloud (Voint cloud), representing each 3D point as a set of features extracted from several view-points. This novel 3D Voint cloud representation combines the compactness of 3D point cloud representation with the natural view-awareness of multi-view representation. Naturally, we can equip this new representation with convolutional and pooling operations. We deploy a Voint neural network (VointNet) to learn representations in the Voint space. Our novel representation achieves state-of-the-art performance on 3D classification, shape retrieval, and robust 3D part segmentation on standard benchmarks ( ScanObjectNN, ShapeNet Core55, and ShapeNet Parts).</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2111.15363" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2111.15363.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/voint-cloud/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/vointcloud" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/18s51teIrTZC6ePmj3VOwz9SXf8xymeYK/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://youtu.be/FKDYoOQDaiM" target="_blank" rel="noopener">
  Video
</a>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://openreview.net/forum?id=IpGgfpMucHj" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/silvio-giancola/">Silvio Giancola</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="http://iccv2021.thecvf.com"><strong>ICCV&rsquo;21</strong></a>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/mvtn-iccv/">
      <img src="/publication/mvtn-iccv/featured_huf4656a799e2497cb8f09eea9d3f07f3b_75978_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/mvtn-iccv/">MVTN: Multi-View Transformation Network for 3D Shape Recognition</a>
  </h3>

  
  <div class="article-style">
    <p>Multi-view projection methods have demonstrated their ability to reach state-of-the-art performance on 3D shape recognition. Those methods learn different ways to aggregate information from multiple views. However, the camera view-points for those views tend to be heuristically set and fixed for all shapes. To circumvent the lack of dynamism of current multi-view methods, we propose to learn those view-points. In particular, we introduce the Multi-View Transformation Network (MVTN) that regresses optimal view-points for 3D shape recognition, building upon advances in differentiable rendering. As a result, MVTN can be trained end-to-end along with any multi-view network for 3D shape classification. We integrate MVTN in a novel adaptive multi-view pipeline that can render either 3D meshes or point clouds. MVTN exhibits clear performance gains in the tasks of 3D shape classification and 3D shape retrieval without the need for extra training supervision. In these tasks, MVTN achieves state-of-the-art performance on ModelNet40, ShapeNet Core55, and the most recent and realistic ScanObjectNN dataset (up to 6% improvement). Interestingly, we also show that MVTN can provide network robustness against rotation and occlusion in the 3D domain.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2011.13244" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2011.13244.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/mvtn-iccv/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/MVTN" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1-dQnztL21U0TcDoPZGx5r-_GWxzEDK-r/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1029t_kLdbklGBxz8qflTbQJHJxn_3XsM/view?usp=sharing" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://youtu.be/1zaHx8ztlhk" target="_blank" rel="noopener">
  Video
</a>





  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/salman-alsubaihi/">Salman Alsubaihi</a></span>, <span><a href="/authors/adel-bibi/">Adel Bibi</a></span>, <span><a href="/authors/modar-alfadly/">Modar Alfadly</a></span>, <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://sites.google.com/connect.hku.hk/robustML-2021/home"><em>ICLR&rsquo;21</em> RobustML Workshop</a>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/etb-iclr21/">
      <img src="/publication/etb-iclr21/featured_hu0f3e3fe75b446ab3c3f9d86c9d28bbbe_53451_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/etb-iclr21/">Expected Tight Bounds for Robust Training</a>
  </h3>

  
  <div class="article-style">
    <p>Training Deep Neural Networks (DNNs) that are robust to norm bounded adversarial attacks remains an elusive problem. While verification based methods are generally too expensive to robustly train large networks, it was demonstrated in Gowal et al that bounded input intervals can be inexpensively propagated per layer through large networks. This interval bound propagation (IBP) approach led to high robustness and was the first to be employed on large networks. However, due to the very loose nature of the IBP bounds, particularly for large networks, the required training procedure is complex and involved. In this paper, we closely examine the bounds of a block of layers composed of an affine layer followed by a ReLU nonlinearity followed by another affine layer. To this end, we propose expected bounds, true bounds in expectation, that are provably tighter than IBP bounds in expectation. We then extend this result to deeper networks through blockwise propagation and show that we can achieve orders of magnitudes tighter bounds compared to IBP. With such tight bounds, we demonstrate that a simple standard training procedure can achieve the best robustness-accuracy trade-off across several architectures on both MNIST and CIFAR10.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1905.12418" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.dropbox.com/s/svov4uoph170p6d/ETB-ICLRW2021.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/etb-iclr21/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ModarTensai/ptb" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1j9MhKzIBbJ3a3YgAI98-Fg3ehoD5MfCb/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://sites.google.com/connect.hku.hk/robustML-2021/home" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/sara-rojas/">Sara Rojas</a></span>, <span><a href="/authors/ali-thabet/">Ali Thabet</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://eccv2020.eu/"><strong>ECCV&rsquo;20</strong></a>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/advpc-arxive/">
      <img src="/publication/advpc-arxive/featured_hu3b50bf3356de4594dfbf595d0d6b623e_337816_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/advpc-arxive/">AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds</a>
  </h3>

  
  <div class="article-style">
    <p>Deep neural networks are vulnerable to adversarial attacks, in which imperceptible perturbations to their input lead to erroneous network predictions. This phenomenon has been extensively studied in the image domain, and has only recently been extended to 3D point clouds. In this work, we present novel data-driven adversarial attacks against 3D point cloud networks. We aim to address the following problems in current 3D point cloud adversarial attacks: they do not transfer well between different networks, and they are easy to defend against via simple tatistical methods. To this extent, we develop a new point cloud attack (dubbed AdvPC) that exploits the input data distribution by adding an adversarial loss, after Auto-Encoder reconstruction, to the objective it optimizes. AdvPC leads to perturbations that are resilient against current defenses, while remaining highly transferable compared to state-of-the-art attacks. We test AdvPC using four popular point cloud networks: PointNet, PointNet++ (MSG and SSG), and DGCNN. Our proposed attack increases the attack success rate by up to 40% for those transferred to unseen networks (transferability), while maintaining a high success rate on the attacked network. AdvPC also increases the ability to break defenses by up to 38% as compared to other baselines on the ModelNet40 dataset.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1912.00461" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1912.00461.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/advpc-arxive/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/AdvPC" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1ZDg-39cBYcN9T-5mKfAcMD-QiF3scGtQ/view?usp=sharing" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://youtu.be/Aq1PPcbhG8Y" target="_blank" rel="noopener">
  Video
</a>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570239.pdf" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    August 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://eccv20-adv-workshop.github.io/"><em>ECCV&rsquo;20</em> Workshop on Adversarial Robustness in the Real World</a> <strong>[Best paper award]</strong>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/sr-iccv19/">
      <img src="/publication/sr-iccv19/featured_hu4065b3a075ab9aa93ce17be2c1104f9e_458616_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/sr-iccv19/">Towards Analyzing Semantic Robustness of Deep Neural Networks</a>
  </h3>

  
  <div class="article-style">
    <p>Despite the impressive performance of Deep Neural Networks (DNNs) on various vision tasks, they still exhibit erroneous high sensitivity toward semantic primitives (e.g. object pose). We propose a theoretically grounded analysis for DNNs robustness in the semantic space. We qualitatively analyze different DNNs semantic robustness by visualizing the DNN global behavior as semantic maps and observe interesting behavior of some DNNs. Since generating these semantic maps does not scale well with the dimensionality of the semantic space, we develop a bottom-up approach to detect robust regions of DNNs. To achieve this, We formalize the problem of finding robust semantic regions of the network as optimization of integral bounds and develop expressions for update directions of the region bounds. We use our developed formulations to quantitatively evaluate the semantic robustness of different famous network architectures. We show through extensive experimentation that several networks, though trained on the same dataset and while enjoying comparable accuracy, they do not necessarily perform similarly in semantic robustness. For example, InceptionV3 is more accurate despite being less semantically robust than ResNet50. We hope that this tool will serve as the first milestone towards understanding the semantic robustness of DNNs.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1904.04621.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/sr-iccv19/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/semantic-robustness" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1HypbEcQ5EbubWgHxCnSnor3neGHP2ijg/view?usp=sharing" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://youtu.be/rf5ynrBap2Q" target="_blank" rel="noopener">
  Video
</a>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://eccv20-adv-workshop.github.io/" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/matthias-muller/">Matthias Muller</a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In <a href="https://aaai.org/Conferences/AAAI-20/"><strong>AAAI</strong> 2020</a> <strong>[spotlight]</strong>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/sada-aaai20/">
      <img src="/publication/sada-aaai20/featured_hu128a3b49411c978b40e78c7999be2415_618457_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/sada-aaai20/">SADA: Semantic Adversarial Diagnostic Attacks for Autonomous Applications</a>
  </h3>

  
  <div class="article-style">
    <p>One major factor impeding more widespread adoption of deep neural networks (DNNs) is their lack of robustness, which is essential for safety-critical applications such as autonomous driving. This has motivated much recent work on adversarial attacks for DNNs, which mostly focus on pixel-level perturbations void of semantic meaning. In contrast, we present a general framework for adversarial attacks on trained agents, which covers semantic perturbations to the environment of the agent performing the task as well as pixel-level attacks. To do this, we re-frame the adversarial attack problem as learning a distribution of parameters that always fools the agent. In the semantic case, our proposed adversary (denoted as BBGAN) is trained to sample parameters that describe the environment with which the black-box agent interacts, such that the agent performs its dedicated task poorly in this environment. We apply BBGAN on three different tasks, primarily targeting aspects of autonomous navigation: object detection, self-driving, and autonomous UAV racing. On these tasks, BBGAN can generate failure cases that consistently fool a trained agent.</p>
  </div>
  

  
  <div class="btn-links">
    





  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1812.02132" target="_blank" rel="noopener">
  Preprint
</a>




  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aaai.org/Papers/AAAI/2020GB/AAAI-HamdiA.1281.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/sada-aaai20/cite.bib">
  Cite
</button>


  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/ajhamdi/SADA" target="_blank" rel="noopener">
  Code
</a>






  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1AbMZyIHDmjbArVwT6AQ6XbWMMPDDM-Yw/view?usp=sharing" target="_blank" rel="noopener">
  Poster
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://drive.google.com/file/d/1xRnytHRXzEkVa5dEeBkAZCE3fWZ91me4/view?usp=sharing" target="_blank" rel="noopener">
  Slides
</a>



  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=clguL24kVG0&amp;feature=youtu.be" target="_blank" rel="noopener">
  Video
</a>



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/https://doi.org/10.1609/aaai.v34i07.6722" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In arxive
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ian-arxive/">
      <img src="/publication/ian-arxive/featured_hu6a5e84e70ec45a7ec56e41aab4651b0d_979162_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ian-arxive/">IAN: Combining Generative Adversarial Networks for Imaginative Face Generation</a>
  </h3>

  
  <div class="article-style">
    <p>Generative Adversarial Networks (GANs) have gained momentum for their ability to model image distributions. They learn to emulate the training set and that enables sampling from that domain and using the knowledge learned for useful applications. Several methods proposed enhancing GANs, including regularizing the loss with some feature matching. We seek to push GANs beyond the data in the training and try to explore unseen territory in the image manifold. We first propose a new regularizer for GAN based on K-nearest neighbor (K-NN) selective feature matching to a target set Y in high-level feature space, during the adversarial training of GAN on the base set X, and we call this novel model K-GAN. We show that minimizing the added term follows from cross-entropy minimization between the distributions of GAN and the set Y. Then, We introduce a cascaded framework for GANs that try to address the task of imagining a new distribution that combines the base set X and target set Y by cascading sampling GANs with translation GANs, and we dub the cascade of such GANs as the Imaginative Adversarial Network (IAN). We conduct an objective and subjective evaluation for different IAN setups in the addressed task and show some useful applications for these IANs, like manifold traversing and creative face generation for characters&rsquo; design in movies or video games.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1904.07916.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/ian-arxive/cite.bib">
  Cite
</button>















  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <strong>[MS Thesis]</strong>
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ms-thesis/">
      <img src="/publication/ms-thesis/featured_hu92aa4dd69ac3502b78628e5b5629013e_20510_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ms-thesis/">Cascading Generative Adversarial Networks for Targeted Imagination</a>
  </h3>

  
  <div class="article-style">
    <p>Abundance of labelled data played a crucial role in the recent developments in computer vision, but that faces problems like scalability and transferability to the wild. One alternative approach is to utilize the data without labels, i.e. unsupervised learning, in learning valuable information and put it in use to tackle vision problems. Generative Adversarial Networks (GANs) have gained momentum for their ability to model image distributions in unsupervised manner. They learn to emulate the training set and that enables sampling from that domain and using the knowledge learned for useful applications. Several methods proposed enhancing GANs, including regularizing the loss with some feature matching. We seek to push GANs beyond the data in the training and try to explore unseen territory in the image manifold. We first propose a new regularizer for GAN based on K-Nearest Neighbor (K-NN) selective feature matching to a target set Y in high-level feature space, during the adversarial training of GAN on the base set X, and we call this novel model K-GAN. We show that minimizing the added term follows from cross-entropy minimization between the distributions of GAN and set Y. Then, we introduce a cascaded framework for GANs that try to address the task of imagining a new distribution that combines the base set X and target set Y by cascading sampling GANs with translation GANs, and we dub the cascade of such GANs as the Imaginative Adversarial Network (IAN). Several cascades are trained on a collected dataset Zoo-Faces and generated innovative samples are shown, including from K-GAN cascade. We conduct an objective and subjective evaluation for different IAN setups in the addressed task of generating innovative samples and we show the effect of regularizing GAN on different scores. We conclude with some useful applications for these IANs, like multi-domain manifold traversing.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://repository.kaust.edu.sa/bitstream/handle/10754/627557/Thesis_Hamdi_updated.pdf?sequence=1&amp;isAllowed=y" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/ms-thesis/cite.bib">
  Cite
</button>















  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      <strong>[Granted]</strong> US Patent US9899957B2
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/us-patent18/">
      <img src="/publication/us-patent18/featured_hu1adffba41ce179ece3008d540733475e_809371_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/us-patent18/">Smart dust-cleaner and cooler for solar PV panels</a>
  </h3>

  
  <div class="article-style">
    <p>The smart dust-cleaner and cooler for solar photo-voltaic (PV) panels is a smooth transparent shield with low absorption coefficient (such as a plastic sheet) placed on top of the PV panel to facilitate removal of dust particulates. Two membrane vibrators (MVs) are placed on opposite sides of the PV panel. The vibrators have the ability to shake and resonate the transparent shield, dislodging the dust particulates from their positions. A compressor powered by the PV panel compresses air before a dust cleaning/cooling process, in which a short duration release of the compressed air creates an air stream over the PV panel that removes the loose dust particulates and cools the PV panel to enhance performance. Using a microcontroller-based timer, the dust cleaning/cooling process is timed for daily operation before noon, when the PV panel temperature is at its peak to maximize PV panel efficiency at maximum irradiance time.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://patentimages.storage.googleapis.com/63/40/8b/1eeb1a81c5c767/US9899957.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/us-patent18/cite.bib">
  Cite
</button>












  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://patents.google.com/patent/US9899957B2/en" target="_blank" rel="noopener">
  Source Document
</a>




  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/abdullah-hamdi/"><strong>Abdullah Hamdi</strong></a></span>, <span><a href="/authors/bernard-ghanem/">Bernard Ghanem</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In arxive
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/filter-arxive/">
      <img src="/publication/filter-arxive/featured_hu11c9f5f56a696ee7b0879e6f63d61f0c_119363_918x517_fill_q90_lanczos_center_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/filter-arxive/">Learning Rotation for Kernel Correlation Filter</a>
  </h3>

  
  <div class="article-style">
    <p>Kernel Correlation Filters have shown a very promising scheme for visual tracking in terms of speed and accuracy on several benchmarks. However it suffers from problems that affect its performance like occlusion, rotation and scale change. This paper tries to tackle the problem of rotation by reformulating the optimization problem for learning the correlation filter. This modification (RKCF) includes learning rotation filter that utilizes circulant structure of HOG feature to guesstimate rotation from one frame to another and enhance the detection of KCF. Hence it gains boost in overall accuracy in many of OBT50 detest videos with minimal additional computation.</p>
  </div>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1708.03698.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/filter-arxive/cite.bib">
  Cite
</button>















  </div>
  

</div>

      
    

    

  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="news" class="home-section wg-news   "  >
    <div class="container">
      


<div class="row">
    
    <div class="col-lg-12 section-heading" style="text-align: center;">
        <h1>News</h1>
    </div>
    

    <div class="col-lg-12">
        
    </div>

    <style>
        #news-table td:first-child {
            width: 1%;
            white-space: nowrap;
            font-weight: bold;
            text-align: center;
             
        }
    </style>

    
    <table id="news-table">
        <tbody>
            
            
            <tr>
                
                <td>[2023-07-09]</td>
                
                <td>
                    
                    Gave a talk at Vincent Sitzmann's group at MIT about  <a
                        href="https://docs.google.com/presentation/d/1v3NG8ZrvGhHtu8hW3MM7xWBb0ExuEneq/edit?usp=sharing&amp;ouid=110685010799138644663&amp;rtpof=true&amp;sd=true">Learning 3D with multi-view supervision: from AlexNet to Stable Diffusion</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-07-14]</td>
                
                <td>
                    
                    Our  <a
                        href="https://arxiv.org/abs/2212.06969">EgoLoc</a>
                    
                     paper accepted at  <a
                        href="https://iccv2023.thecvf.com/">ICCV 2023</a>
                    
                     conference in Paris, France as an  <a
                        href="">oral</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-07-02]</td>
                
                <td>
                    
                    Our  <a
                        href="https://guochengqian.github.io/project/magic123/">Magic123</a>
                    
                     paper released and made a buzz at the  <a
                        href="https://twitter.com/_akhaliq/status/1675684794653351936?s=46&amp;t=JqBv8mqM4L3ZtBb7bNcb5A">research community</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-06-19]</td>
                
                <td>
                    
                    Lead organizing  <a
                        href="https://3dmv2023.github.io/">3DMV</a>
                    
                     workshop at  <a
                        href="https://cvpr2023.thecvf.com/">CVPR 2023</a>
                    
                     ( <a
                        href="https://drive.google.com/drive/folders/16ilo2f1ujuhM9ooQBZj8b385DeJoCiVV?usp=sharing">picutres, panel discussions</a>
                    
                    )
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-06-19]</td>
                
                <td>
                    
                    Presneted our  <a
                        href="https://openaccess.thecvf.com/content/CVPR2023W/CVSports/html/Held_VARS_Video_Assistant_Referee_System_for_Automated_Soccer_Decision_Making_CVPRW_2023_paper.html">VARS</a>
                    
                     paper at  <a
                        href="https://cvpr2023.thecvf.com/">CVPR 2023</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-06-19]</td>
                
                <td>
                    
                    Won the first place at VQ3D challenge of  <a
                        href="https://ego4d-data.org/workshops/cvpr23/">Ego4D</a>
                    
                     workshop at  <a
                        href="https://cvpr2023.thecvf.com/">CVPR 2023</a>
                    
                     ( <a
                        href="https://drive.google.com/file/d/1Xee76XVbzPogIdxRlA8XbGUX22UWiUeP/view?usp=sharing">picutres</a>
                    
                    )
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-05-02]</td>
                
                <td>
                    
                    Started my postdoc at  <a
                        href="https://www.robots.ox.ac.uk/~vgg/">VGG lab</a>
                    
                    ,  <a
                        href="https://www.ox.ac.uk/">University of Oxford</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td colspan="2">
                    ~ The beginning of my postdoc ~
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-05-02]</td>
                
                <td>
                    
                    Presneted our  <a
                        href="https://arxiv.org/abs/2111.15363">Voint cloud</a>
                    
                     paper at  <a
                        href="https://iclr.cc/Conferences/2023">ICLR 2023</a>
                    
                     ( <a
                        href="https://drive.google.com/drive/folders/1-SYgyc3vEBQHSsuIiFzaALOIQMMLbS0R?usp=sharing">picutres</a>
                    
                    )
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-04-10]</td>
                
                <td>
                    
                    Successsfully defended my PhD dissertation titled  <a
                        href="https://repository.kaust.edu.sa/handle/10754/691198">Towards Designing Robust Deep Learning Models for 3D Understanding</a>
                    
                     ( <a
                        href="https://drive.google.com/drive/folders/1-YzscX2ygp9Lp9OW3ap_yprHTC-Wzgfz?usp=sharing">picutres</a>
                    
                    ).
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-02-19]</td>
                
                <td>
                    
                    Gave a talk and presented a poster at  <a
                        href="https://cemse.kaust.edu.sa/ai/aii-symp-2023">KAUST AI Rising Stars Symposium</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-02-14]</td>
                
                <td>
                    
                    Gave a talk about  <a
                        href="https://docs.google.com/presentation/d/11X-8PS4Ghi-J_H-FBvcv8Pd0QJz2i9BAZytfetCXvcc/edit?usp=sharing">Stable Diffusion and Beyond</a>
                    
                     at KAUST.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2023-01-21]</td>
                
                <td>
                    
                    Our  <a
                        href="https://arxiv.org/abs/2111.15363">Voint Cloud</a>
                    
                     paper accepted as poster at  <a
                        href="https://iclr.cc/Conferences/2023">ICLR 2023</a>
                    
                     conference, Rawanda
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-12-16]</td>
                
                <td>
                    
                    Our CVPR 2023 workshop proposal `3DMV: Learning 3D with multi-view supervision`  <a
                        href="https://twitter.com/Eng_Hemdi/status/1603497695674789888?s=20&amp;t=4H2GGD46ZbFySBR7WPNv_w">was acepted to CVPR 2023</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-10-27]</td>
                
                <td>
                    
                    I lead a team `Ain Sports` to win the  <a
                        href="https://drive.google.com/drive/folders/1L8VGVQ0bceDz4UDRwEefYrV6PmReWca_?usp=share_link">2'nd place</a>
                    
                     at the Thakaa  <a
                        href="https://twitter.com/thakaa_center/status/1585627910206939136?s=21">AI for sposrts competetion</a>
                    
                    , with a total prize of SR 250K
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-10-24]</td>
                
                <td>
                    
                    We won the 1'st place in  <a
                        href="https://ego4d-data.org/workshops/eccv22/">Ego4D VQ3D challenge</a>
                    
                     at ECCV2022
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-09-28]</td>
                
                <td>
                    
                    I represented KAUST at the  <a
                        href="https://drive.google.com/drive/folders/1klU-E_rJujvG6DQvmf1a_ATgI54x-Yj9?usp=sharing"> Saudi-Chinese Youths Audio-visual Communication Workshop</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-09-13]</td>
                
                <td>
                    
                    I represented KAUST at the  <a
                        href="https://drive.google.com/drive/folders/1-N7uxd9OmOYMhFHgN_6aIHGbf0nePO-J?usp=sharing">2'nd global AI summit in Riyadh</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-08-17]</td>
                
                <td>
                    
                    I gave a talk at  <a
                        href="https://geometry.stanford.edu/index.html">Stanford Geometric Computing group</a>
                    
                     on `the robustness of 3D understanding methods`.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-08-04]</td>
                
                <td>
                    
                    I supervised an intern to our group `Faisal Alzahrani` to win at a  <a
                        href="https://drive.google.com/file/d/1Nxp9k6CmM1EpegSwBogzxx_H1uFkr6_6/view?usp=sharing">poster competetion</a>
                    
                     at KAUST for his work on a TPAMI extension to MVTN.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-07-02]</td>
                
                <td>
                    
                    My first child `Jamal` was born
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-06-19]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://cvpr2022.thecvf.com/">CVPR 2022</a>
                    
                     ,Virtually.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-06-17]</td>
                
                <td>
                    
                    Gave a talk at  <a
                        href="https://niessnerlab.org/">TUM</a>
                    
                     AI group at Munich , Germany about  <a
                        href="https://docs.google.com/presentation/d/1LwvAng0m_sQL_mOluvriC1CeG5KbP8Zy/edit?usp=sharing&amp;ouid=110685010799138644663&amp;rtpof=true&amp;sd=true">`Pix2Rad: learning to Generate 3D Shapes Radiance Fields from Few Images`</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-05-15]</td>
                
                <td>
                    
                    I was hosted on  <a
                        href="https://twitter.com/jeddah_radio/status/1525747111656136704?s=21">Jeddah Radio</a>
                    
                     to talk about AI as a carear and advice for college students.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-02-15]</td>
                
                <td>
                    
                    I was awarded the prestegious  <a
                        href="https://www.kaust.edu.sa/en/news/kaust-welcomes-ibn-rushd-scholars">`Ibn Rushd Postdoc Fellowship Award`</a>
                    
                     by KAUST amoung 12 Saudis from all over the world.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2022-02-01]</td>
                
                <td>
                    
                    I started a research internship with Prof.  <a
                        href="https://niessnerlab.org/">Matthias Niessner</a>
                    
                     in TUM, Munich.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-11-17]</td>
                
                <td>
                    
                    I was awarded  <a
                        href="https://cemse.kaust.edu.sa/news/cemse-student-research-excellence-awards-and-student-academic-accomplishment-awards-winners">`CEMSE Student Research Excellence Award`</a>
                    
                     at KAUST for the 2<sup>nd</sup> time.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-10-12]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://iccv2021.thecvf.com/home">ICCV 2021</a>
                    
                     ,Virtual to present  <a
                        href="https://arxiv.org/abs/1912.00461">MVTN</a>
                    
                     paper.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-10-06]</td>
                
                <td>
                    
                    I was hosted on the mainstream  <a
                        href="https://pca.st/9ftdm9fd">podcast `Thmaniah` to talk about AI bias</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-09-23]</td>
                
                <td>
                    
                    I successfully passed the  <a
                        href="https://docs.google.com/presentation/d/1-2w_o9LW4MsP2rMPw70TCpVnfFT-7bq0/edit?usp=sharing&amp;ouid=110685010799138644663&amp;rtpof=true&amp;sd=true">phd proposal exam</a>
                    
                     titled: `Towards Designing Robust Deep Learning Models for 3D Understanding`.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-06-18]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://cvpr2021.thecvf.com/">CVPR 2021</a>
                    
                     Virtually.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-06-01]</td>
                
                <td>
                    
                    Gave a  <a
                        href="https://youtu.be/pWwzOmbOEUQ">TedX talk about AI inequality</a>
                    
                     at KAUST.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-05-14]</td>
                
                <td>
                    
                    One paper ( <a
                        href="https://arxiv.org/abs/2011.13244">MVTN</a>
                    
                    ) accepted as poster at  <a
                        href="https://iccv2021.thecvf.com/home">ICCV 2021</a>
                    
                     conference, Virtual
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-03-21]</td>
                
                <td>
                    
                    I was hosted on  <a
                        href="https://lnkd.in/drUhcSM">Elm Al-Heal podcast to talk about AI history and application</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2021-02-14]</td>
                
                <td>
                    
                    One paper ( <a
                        href="https://arxiv.org/abs/1905.12418">Tight Bounds</a>
                    
                    ) accepted as poster at  <a
                        href="https://sites.google.com/connect.hku.hk/robustml-2021/home">ICLR 2021 Workshops</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-12-15]</td>
                
                <td>
                    
                    Gave a seminar about  <a
                        href="https://youtu.be/lZDXAe5IJJ8">`3D attacks on deep learning models`</a>
                    
                     to  <a
                        href="https://iith.acm.org/">ACM IIT, Hyderabad chapter</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-12-10]</td>
                
                <td>
                    
                    Winner of the  <a
                        href="https://neomchallenge.com/en.html">NEOM AI Challenge</a>
                    
                    , Entertainment track (AI-Sports team).
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-11-17]</td>
                
                <td>
                    
                    I was awarded  <a
                        href="https://cemse.kaust.edu.sa/news/cemse-student-research-excellence-awards-and-student-academic-accomplishment-awards-winners">`CEMSE Student Research Excellence Award`</a>
                    
                     at KAUST.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-10-27]</td>
                
                <td>
                    
                    Gave  <a
                        href="https://youtu.be/FrPHeY9cLVk"> Introduction to Deep Learning Workshop</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-10-04]</td>
                
                <td>
                    
                    Gave a  <a
                        href="https://youtu.be/qeqja3zL4eg">seminar about my recent papers on 3D Adversarial Attacks</a>
                    
                     on `Computer Vision talks` serirs
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-10-04]</td>
                
                <td>
                    
                    I was hosted on  <a
                        href="https://youtu.be/qZwhU2-H4OQ">Jeddah Radio</a>
                    
                     to talk about AI and it‚Äôs positive and negative implications
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-06-09]</td>
                
                <td>
                    
                    Gave  <a
                        href="https://youtu.be/qoBdMrqVhMg"> Introduction to Deep Learning Workshop</a>
                    
                     to +600 attendees in KFUPM innovation club.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-07-24]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://eccv2020.eu/">ECCV 2020</a>
                    
                     ,Virtual to present  <a
                        href="https://arxiv.org/abs/1912.00461">AdvPC</a>
                    
                     paper.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-07-23]</td>
                
                <td>
                    
                    ( <a
                        href="https://arxiv.org/abs/1904.04621">Semantic Robsutness</a>
                    
                    ) paper wins Best Paper Award at  <a
                        href="https://eccv20-adv-workshop.github.io/">Workshop on Adversarial Robustness in the Real World</a>
                    
                     in  <a
                        href="https://eccv2020.eu/">ECCV 2020</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-06-18]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://cvpr2020.thecvf.com/">CVPR 2020</a>
                    
                     Virtually.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-04-14]</td>
                
                <td>
                    
                    One paper ( <a
                        href="https://arxiv.org/abs/1912.00461">AdvPC</a>
                    
                    ) accepted as poster at  <a
                        href="https://eccv2020.eu/">ECCV 2020</a>
                    
                     conference, Virtual
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2020-01-25]</td>
                
                <td>
                    
                    Accepted for a research internship at Adobe, London with Prof.  <a
                        href="http://www0.cs.ucl.ac.uk/staff/n.mitra/">Niloy Mitra</a>
                    
                     (canceled last minute due to COVID 19)
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2019-12-09]</td>
                
                <td>
                    
                    Gave a two hours talk on  <a
                        href="https://docs.google.com/presentation/d/1TSOcUgpR7FhaXWC3CELV1YAEQRXXmNAB/edit?usp=sharing&amp;ouid=110685010799138644663&amp;rtpof=true&amp;sd=true">Neural Rendering</a>
                    
                     in an  <a
                        href="https://github.com/IVUL-KAUST/GroupReading">IVUL's group meeting</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2019-11-07]</td>
                
                <td>
                    
                    One paper ( <a
                        href="https://ojs.aaai.org/index.php/AAAI/article/view/6722">SADA</a>
                    
                    ) accepted for spotlight at  <a
                        href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a>
                    
                     conference, New York
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2019-06-18]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://iccv2019.thecvf.com/">ICCV 2019</a>
                    
                     in Seoul, South Korea to present at  <a
                        href="http://xai.unist.ac.kr/workshop/2019/">Explainable AI workshop</a>
                    
                     
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2019-06-18]</td>
                
                <td>
                    
                    Attended  <a
                        href="https://cvpr2019.thecvf.com/">CVPR 2019</a>
                    
                     at Long Beach, Calfornia
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2019-03-01]</td>
                
                <td>
                    
                    Gave a lecture  <a
                        href="https://youtu.be/FrPHeY9cLVk">Lecture on GANs</a>
                    
                    , EE354 (Intro to Computer Vision), KAUST
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-08-08]</td>
                
                <td>
                    
                    Volunteered as an  <a
                        href="https://www.facebook.com/KAUSTOfficial/posts/10156531255664291">orientation leader</a>
                    
                     to help new  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                     students
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-06-10]</td>
                
                <td>
                    
                    Started my PhD degree at  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                     with  <a
                        href="http://bernardghanem.com">Bernard Ghanem</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-04-10]</td>
                
                <td>
                    
                    Started  <a
                        href="https://fihm.ai/">fihm.ai</a>
                    
                     to be the Arbic AI hub
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-03-25]</td>
                
                <td>
                    
                    Awarded  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                     Fellowship with full tuition support for a PhD degree
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-02-20]</td>
                
                <td>
                    
                    Granted a  <a
                        href="https://patents.google.com/patent/US9899957B2/en">US Patent</a>
                    
                     on invention: `Smart dust-cleaner and cooler for solar PV panels`
                </td>
                
            </tr>
            
            <tr>
                
                <td colspan="2">
                    ~ The beginning of my PhD program ~
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2018-04-12]</td>
                
                <td>
                    
                    Successfully defended my  <a
                        href="https://repository.kaust.edu.sa/handle/10754/627557">Master‚Äôs thesis</a>
                    
                     on  <a
                        href="https://docs.google.com/presentation/d/1R27tw0-Y7JoOq89h7l3cSUkTxUJc2Gex/edit?usp=sharing&amp;ouid=110685010799138644663&amp;rtpof=true&amp;sd=true">GANs for imaginative generation</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2017-11-25]</td>
                
                <td>
                    
                    I obtained  <a
                        href="https://drive.google.com/file/d/10GSWOOG81oDGNhwuemF6OSDRs5nA04Dq/view?usp=sharing">107/120 in English TOEFEL IBT test</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2017-05-21]</td>
                
                <td>
                    
                    Won the 1<sup>st</sup> place in  <a
                        href="https://drive.google.com/file/d/1G6chg6Ux02cRtAd9DjAJS1Y4GUl01sdX/view?usp=sharing">Entrepreneurship Super Steam challenge</a>
                    
                     for Saudi universities in KAUST, $ 8,000 prize, startup idea: VR labs.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2017-01-07]</td>
                
                <td>
                    
                    Attended the Winter Enrichment Program  <a
                        href="https://enrichment.kaust.edu.sa">WEP 2017</a>
                    
                     at  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-11-03]</td>
                
                <td>
                    
                    Completed the  <a
                        href="https://www.coursera.org/learn/machine-learning/">Coursera-Stanford</a>
                    
                     course on Machine Learning
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-10-03]</td>
                
                <td>
                    
                    Developing visual object tracking and orientation detection vision for UAVs, participating with KAUST team that wins  <a
                        href="https://www.mbzirc.com/">MBZIRC</a>
                    
                     international competition.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-08-21]</td>
                
                <td>
                    
                    Started my Master's degree at  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                     and joined  <a
                        href="https://ivul.kaust.edu.sa">IVUL</a>
                    
                    's research group
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-07-10]</td>
                
                <td>
                    
                    Awarded  <a
                        href="https://kaust.edu.sa">KAUST</a>
                    
                     Fellowship with full tuition support for an MS degree
                </td>
                
            </tr>
            
            <tr>
                
                <td colspan="2">
                    ~ The beginning of my master&#39;s program ~
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-05-24]</td>
                
                <td>
                    
                    Graduated from  <a
                        href="http://www.kfupm.edu.sa">KFUPM</a>
                    
                     with a BSc in Electrical Engineering
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2016-05-04]</td>
                
                <td>
                    
                    Leading Best Senior Design Project:  <a
                        href="https://drive.google.com/file/d/1MyV9fsiJpkFJaXum0I_f5y9Jqd3WauZf/view?usp=sharing">`Low cost automatic controlled drones`</a>
                    
                    
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2015-06-14]</td>
                
                <td>
                    
                    Started my summer internship at  <a
                        href="https://www.ge.com/sa/">General Electric, Power Generation Services</a>
                    
                     with  <a
                        href="https://sa.linkedin.com/in/hassan-elokdi-996ba936?original_referer=https%3A%2F%2Fwww.google.com%2F">Hassan Elokdy</a>
                    
                     in Dammam, Saudi Arabia
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2015-07-20]</td>
                
                <td>
                    
                    Member in KFUPM president highest advisory student board, and chairman of student activities development committee in the board.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2015-04-20]</td>
                
                <td>
                    
                    Founder and president of  <a
                        href="https://twitter.com/kfupminov">KFUPM Innovation Club</a>
                    
                     (+200 members).
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2015-07-20]</td>
                
                <td>
                    
                     (+200 members).
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2014-09-07]</td>
                
                <td>
                    
                    The 1<sup>st</sup> place winner in  <a
                        href="https://nbhaward.bh/">Nassir Bin Hamad international youth creativity award</a>
                    
                     in science for invention in solar dust cleaning. US Patent:  <a
                        href="https://patents.google.com/patent/US9899957B2/en">US9899957B2</a>
                    
                    .
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2014-07-21]</td>
                
                <td>
                    
                    Started an Exchange program at  <a
                        href="https://www.tamu.edu/">Texas A&M</a>
                    
                    , College Station, TX. I finished 14 credit hours with  <a
                        href="https://drive.google.com/file/d/1Z5qz3yRCMVfUE-EfnCznh8XanNoGHm0K/view?usp=sharing">perfect GPA</a>
                    
                     (4.0/4.0) 
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2014-05-01]</td>
                
                <td>
                    
                    Placed 9<sup>th</sup> inventor in the the fifth Scientific conference for higher education in Riyadh, Saudi Arabia
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2011-09-10]</td>
                
                <td>
                    
                    Started my Bachelor's degree at  <a
                        href="http://www.kfupm.edu.sa">KFUPM</a>
                    
                     aiming to be an academic.
                </td>
                
            </tr>
            
            <tr>
                
                <td colspan="2">
                    ~ The beginning of my Bachelor&#39;s program ~
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2011-05-25]</td>
                
                <td>
                    
                    Obtained my  <a
                        href="https://drive.google.com/file/d/1i8IqY1hkVkt5LQHd6QZEo60F8qcPnh6y/view?usp=sharing">high school diploma</a>
                    
                     from  <a
                        href="https://www.alfalah.edu.sa/">Alfalah school</a>
                    
                    , Makkah, with a 100% accumlated grade.
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2010-02-01]</td>
                
                <td>
                    
                    Won the 1<sup>st</sup> place in the national  <a
                        href="https://www.mawhiba.org/Ar/Pages/default.aspx">Mawhiba</a>
                    
                     Chemistry Olympiad 
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2009-07-01]</td>
                
                <td>
                    
                    Won the 3<sup>rd</sup> place in the national  <a
                        href="https://www.mawhiba.org/Ar/Pages/default.aspx">Mawhiba</a>
                    
                     Chemistry Olympiad 
                </td>
                
            </tr>
            
            <tr>
                
                <td>[2008-07-01]</td>
                
                <td>
                    
                    Nominated to represent Saudi Arabia in  <a
                        href="http://www.ijsoweb.org/">International Junior Science Olympiad</a>
                    
                     for most qualified students in the world in Changwon, Korea.
                </td>
                
            </tr>
            
        </tbody>
    </table>
    
</div>
    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="contact" class="home-section wg-contact   "  >
    <div class="container">
      





<div class="row contact-widget">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Contact</h1>
    
  </div>
  <div class="col-12 col-lg-8">
    

    

    
    
      
      
    

    
    <ul class="fa-ul">
      <li>
        <i class="fa-li fas fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email"><a href="mailto:abdullah.hamdi@eng.ox.ac.uk">abdullah.hamdi@eng.ox.ac.uk</a></span>
      </li>
    </ul>
    

    <div class="mb-3">
      <form name="contact" method="POST" action="https://formspree.io/abdullah.hamdi@eng.ox.ac.uk">
        <div class="form-group form-inline">
          <label class="sr-only" for="inputName">Name</label>
          <input type="text" name="name" class="form-control w-100" id="inputName" placeholder="Name" required>
        </div>
        <div class="form-group form-inline">
          <label class="sr-only" for="inputEmail">Email</label>
          <input type="email" name="email" class="form-control w-100" id="inputEmail" placeholder="Email" required>
        </div>
        <div class="form-group">
          <label class="sr-only" for="inputMessage">Message</label>
          <textarea name="message" class="form-control" id="inputMessage" rows="5" placeholder="Message" required></textarea>
        </div>
        <button type="submit" class="btn btn-outline-primary px-3 py-2">Send</button>
      </form>
    </div>
    

    <ul class="fa-ul">

      

      
      <li>
        <i class="fa-li fas fa-phone fa-2x" aria-hidden="true"></i>
        <span id="person-telephone"><a href="tel:&#43;44%207936784058">&#43;44 7936784058</a></span>
      </li>
      

      
      
        
        <li>
          <i class="fa-li fas fa-map-marker fa-2x" aria-hidden="true"></i>
          <span id="person-address">T17 Parks Rd, Oxford, Oxfordshire OX1-3PJ</span>
        </li>
      

      
      <li>
        <i class="fa-li fas fa-compass fa-2x" aria-hidden="true"></i>
        <span>University of Oxford, EIB building, 2&rsquo;nd floor, office: 30.06, T17 Parks Rd, Oxford OX1 3PJ | United Kingdom</span>
      </li>
      

      

      
      <li>
        <i class="fa-li fas fa-calendar-check fa-2x" aria-hidden="true"></i>
        <a href="https://calendly.com/abdullah-hamdi" target="_blank" rel="noopener">Book an appointment</a>
      </li>
      

      
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <i class="fa-li fab fa-twitter fa-2x" aria-hidden="true"></i>
        <a href="https://twitter.com/Eng_Hemdi" target="_blank" rel="noopener">DM Me</a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <i class="fa-li fab fa-skype fa-2x" aria-hidden="true"></i>
        <a href="https://join.skype.com/invite/m11EYsNK5NJR" target="_blank" rel="noopener">Skype Me</a>
      </li>
      

    </ul>

    
    <div class="d-none">
      <input id="map-provider" value="2">
      <input id="map-lat" value="51.761025">
      <input id="map-lng" value="-1.259826">
      <input id="map-dir" value="T17 Parks Rd, Oxford, Oxfordshire OX1-3PJ">
      <input id="map-zoom" value="15">
      <input id="map-api-key" value="">
    </div>
    <div id="map"></div>
    

  </div>
</div>

    </div>
  </section>



      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.0e306e8373c36761cd7c6bcf5dfb6df2.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    ¬© 2019 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
